{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henripal/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import sgld\n",
    "import os\n",
    "import xpbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_string = \"postgres://postgres:1418@localhost/experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n"
     ]
    }
   ],
   "source": [
    "experiments, steps, modelparams = xpbase.initialize(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_desc = {'lr': 0.01,\n",
    "             'a': .2,\n",
    "             'b': 15,\n",
    "             'gamma': .55,\n",
    "             'epochs': 2,\n",
    "             'addnoise': True,\n",
    "             'step_samples': 10,\n",
    "             'percentage_tosample': .1,\n",
    "             'seed': 1}\n",
    "\n",
    "model_desc2 = {'lr': 0.01,\n",
    "             'a': .2,\n",
    "             'b': 20,\n",
    "             'gamma': .55,\n",
    "             'epochs': 2,\n",
    "             'addnoise': True,\n",
    "             'step_samples': 10,\n",
    "             'percentage_tosample': .1,\n",
    "             'seed': 1}\n",
    "\n",
    "model_desc3 = {'lr': 0.01,\n",
    "             'a': .2,\n",
    "             'b': 26,\n",
    "             'gamma': .55,\n",
    "             'epochs': 2,\n",
    "             'addnoise': True,\n",
    "             'step_samples': 10,\n",
    "             'percentage_tosample': .1,\n",
    "             'seed': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = Process(target=sgld.runall, args=(0, model_desc))\n",
    "p2 = Process(target=sgld.runall, args=(1, model_desc2))\n",
    "p3 = Process(target=sgld.runall, args=(2, model_desc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n",
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n",
      "/home/henripal/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py:1654: SAWarning: Property Experiment.steps on Mapper|Experiment|experiments being replaced with new property Experiment.steps; the old property will be discarded\n",
      "  prop,\n",
      "/home/henripal/projects/sgld/sgld/sgld/model.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "/home/henripal/projects/sgld/sgld/sgld/model.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "/home/henripal/projects/sgld/sgld/sgld/model.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 2.407\tAcc: 11.020\tVal Acc: 0.000\n",
      "Epoch: 0\tLoss: 2.267\tAcc: 16.118\tVal Acc: 0.000\n",
      "Epoch: 0\tLoss: 2.226\tAcc: 19.901\tVal Acc: 0.000\n",
      "Epoch: 1\tLoss: 2.336\tAcc: 12.336\tVal Acc: 14.989\n",
      "Total number of steps: 118\n",
      "Epoch: 1\tLoss: 1.667\tAcc: 43.750\tVal Acc: 34.624\n",
      "Total number of steps: 118\n",
      "Epoch: 1\tLoss: 2.226\tAcc: 18.586\tVal Acc: 15.929\n",
      "Total number of steps: 118\n"
     ]
    }
   ],
   "source": [
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisxp = xpbase.session.query(experiments).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(thisxp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ha = xpbase.session.query(steps.model_params).filter(steps.run_id == thisxp.run_id).order_by(steps.step_id.desc()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisxp.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = [x for l in ha[0].values() for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ha[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(firststep.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firststep.experiment is xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.randint(3, size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainacc = xpbase.session.query(steps.trainacc).filter(steps.run_id == 22).all()\n",
    "valacc = xpbase.session.query(steps.valacc).filter(steps.run_id == 22).all()\n",
    "trainloss = xpbase.session.query(steps.trainloss).filter(steps.run_id == 22).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = Figure(data=[Scatter(x=[1, 2, 3], y=[1, 2, 3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.data[0].x.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.data[0].extend([Scatter(x=[4], y=[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(trainacc)\n",
    "plt.plot(valacc)\n",
    "plt.figure()\n",
    "plt.plot(np.log(trainloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withnoise_histo = torch.load(os.path.join(basedir, \n",
    "                                          'withnoise_best_3', 'histo'))\n",
    "nonoise_histo = torch.load(os.path.join(basedir, \n",
    "                                          'nonoise_best_3', 'histo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withnoise_histo_np = sgld.state_dict_histo_2_numpy(withnoise_histo)\n",
    "nonoise_histo_np = sgld.state_dict_histo_2_numpy(nonoise_histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=15)\n",
    "plt.plot(withnoise['loss'], label='Langevin GD')\n",
    "plt.plot(nonoise['loss'], label='SGD')\n",
    "plt.legend()\n",
    "plt.xlabel('training time')\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisy_std = sgld.apply_rolling2D(withnoise_histo_np,\n",
    "                    lambda x: np.std(x, axis=1), 40)\n",
    "clean_std = sgld.apply_rolling2D(nonoise_histo_np,\n",
    "                    lambda x: np.std(x, axis=1), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxi_noisy = np.max(noisy_std, axis=1)\n",
    "maxi_clean = np.max(clean_std, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.semilogy(maxi_noisy, label='Langevin GD')\n",
    "plt.semilogy(maxi_clean, label='SGD')\n",
    "plt.legend()\n",
    "plt.xlabel('training time')\n",
    "plt.ylabel('Max St.Dev. of Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noisy_id = sgld.apply_rolling2D(withnoise_histo_np[:, :2000],\n",
    "                               lambda x: x, 100, stack=False)\n",
    "clean_id = sgld.apply_rolling2D(nonoise_histo_np[:, :2000],\n",
    "                               lambda x: x, 100, stack=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta = sgld.plot_densities(noisy_id[14], n_indices=20, \n",
    "                            n_bins=30, \n",
    "                            alpha=.4,\n",
    "                           burnin=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgld.plot_densities(clean_id[14], n_indices=10,\n",
    "                    n_bins=100,\n",
    "                    alpha=.4, \n",
    "                    delta=delta,\n",
    "                   burnin=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usable_statedict = OrderedDict()\n",
    "for k, v in nonoise_histo[-1].items():\n",
    "    usable_statedict[k] = torch.Tensor(v).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sgld.MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(usable_statedict)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = sgld.make_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proba distribution on notMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotMnist(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filelist = glob.glob(os.path.join(self.root_dir, '**', '*.png'))\n",
    "        new_filelist = []\n",
    "        for file in self.filelist:\n",
    "            try:\n",
    "                io.imread(file)\n",
    "                new_filelist.append(file)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        self.filelist = new_filelist\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.filelist[idx])\n",
    "        image = PIL.Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            return self.transform(image)\n",
    "        return image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notmnist = NotMnist(root_dir = '../data/notMNIST_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 256\n",
    "notmnist_loader = torch.utils.data.DataLoader(NotMnist('../data/notMNIST_small',\n",
    "                                                      transform=transforms.ToTensor()), batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "notmnist_probas = []\n",
    "for data in notmnist_loader:\n",
    "    data = Variable(data, volatile=True)\n",
    "    data = data.cuda()\n",
    "    output = model(data)\n",
    "    notmnist_probas.append(output.max(1)[0].cpu().data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notmnist_probas = np.hstack(notmnist_probas)\n",
    "notmnist_probas = np.exp(notmnist_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(notmnist_probas), np.std(notmnist_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(notmnist_probas, bins=20, density=True, alpha = .8) ;\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('normalized count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proba distribution on mnist (correct and incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "probas = []\n",
    "acc = []\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n",
    "    data = data.cuda()\n",
    "    target = target.cuda()\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1]\n",
    "    proba = output.data.max(1)[0]\n",
    "    probas.append(proba.cpu().numpy())\n",
    "    acc.append(prediction.eq(target.data))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = np.hstack(probas)\n",
    "acc = np.hstack(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_probas = np.exp(probas[acc == 1])\n",
    "incorrect_probas = np.exp(probas[acc == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_probas.shape, incorrect_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(correct_probas), np.std(correct_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(incorrect_probas), np.std(incorrect_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(correct_probas, bins=20, density=True, alpha = .8, label='correct');\n",
    "plt.hist(incorrect_probas, bins=20, density=True, alpha=.8, label='incorrect');\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('normalized counts')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Bayesian. Basic MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_statedict(idx, histo):\n",
    "    usable_statedict = OrderedDict()\n",
    "    for k, v in histo[idx].items():\n",
    "        usable_statedict[k] = torch.Tensor(v).cuda()\n",
    "    return usable_statedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas = []\n",
    "bayes_targets = []\n",
    "\n",
    "for i in np.arange(-1, -20, -1):\n",
    "    model = sgld.MnistModel()\n",
    "    state_dict = make_statedict(i, withnoise_histo)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_probas = np.zeros((10000, 10))\n",
    "    epoch_targets = np.zeros((10000,))\n",
    "\n",
    "    for idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        output = model(data)\n",
    "        proba = output.data\n",
    "        epoch_probas[idx * test_loader.batch_size:(idx + 1) * test_loader.batch_size, :] = proba.cpu().numpy()\n",
    "        epoch_targets[idx * test_loader.batch_size:(idx + 1) * test_loader.batch_size] = target.cpu().data.numpy()\n",
    "        \n",
    "    bayes_probas.append(epoch_probas)\n",
    "    bayes_targets.append(epoch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas = np.stack(bayes_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_targets = bayes_targets[0].astype(int)\n",
    "bayes_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_averaged_probas = np.mean(bayes_probas, axis=0)\n",
    "bayes_averaged_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_max_probas = np.exp(bayes_averaged_probas.max(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_predictions = np.argmax(bayes_averaged_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_correct_probas = bayes_max_probas[bayes_predictions == bayes_targets]\n",
    "bayes_incorrect_probas = bayes_max_probas[bayes_predictions != bayes_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_correct_probas.shape, bayes_incorrect_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bayes_correct_probas), np.std(bayes_correct_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bayes_incorrect_probas), np.std(bayes_incorrect_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(bayes_correct_probas, bins=20, density=True, alpha = .8, label='correct');\n",
    "plt.hist(bayes_incorrect_probas, bins=20, density=True, alpha=.8, label='incorrect');\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('counts')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian. NotMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas_nm = []\n",
    "\n",
    "for i in np.arange(-1, -20, -1):\n",
    "    model = sgld.MnistModel()\n",
    "    state_dict = make_statedict(i, withnoise_histo)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_probas = np.zeros((18724, 10))\n",
    "\n",
    "    for idx, data in enumerate(notmnist_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        data = data.cuda()\n",
    "        output = model(data)\n",
    "        proba = output.data\n",
    "        epoch_probas[idx * notmnist_loader.batch_size:(idx + 1) * notmnist_loader.batch_size, :] = proba.cpu().numpy()\n",
    "        \n",
    "    bayes_probas_nm.append(epoch_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_probas_nm = np.stack(bayes_probas_nm)\n",
    "bayes_averaged_probas_nm = np.mean(bayes_probas_nm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_max_probas_nm = np.exp(bayes_averaged_probas_nm.max(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bayes_max_probas_nm), np.std(bayes_max_probas_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(notmnist_probas, bins=20, density=True, alpha = .8, label='SGD') ;\n",
    "plt.hist(bayes_max_probas_nm, bins=20, density=True, alpha = .8, label='Langevin SGD') ;\n",
    "plt.xlabel('confidence in prediction')\n",
    "plt.ylabel('normalized count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
